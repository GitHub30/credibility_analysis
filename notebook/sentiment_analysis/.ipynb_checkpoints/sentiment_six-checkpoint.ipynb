{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "emotions = [\"happy\", \"sad\", \"disgust\", \"angry\", \"fear\", \"surprise\"]\n",
    "\n",
    "for emo in emotions:\n",
    "    with open(\"{}.json\".format(emo), \"r\") as f:\n",
    "        data.append(json.load(f)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(len(emotions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>html</th>\n",
       "      <th>id</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>user</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>himitan</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420866954891265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@yukyan_MNsy おはようありがとう〜ハンバーグまだあるよ食べにおいで（笑）</td>\n",
       "      <td>2013-01-18T23:59:02</td>\n",
       "      <td>/himitan1109/status/292420866954891265</td>\n",
       "      <td>himitan1109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>himitan</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420700034199552</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@gdgk0x ありがとういらなかったけど（笑）明日もあるけどさすがに飽きるよね（笑）</td>\n",
       "      <td>2013-01-18T23:58:22</td>\n",
       "      <td>/himitan1109/status/292420700034199552</td>\n",
       "      <td>himitan1109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ゆかちん</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420678207033344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@kuwamann0410 おはようステキな目覚めだね♪</td>\n",
       "      <td>2013-01-18T23:58:17</td>\n",
       "      <td>/babys_yuka/status/292420678207033344</td>\n",
       "      <td>babys_yuka</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>コミー♪</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420470807068672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@andy_yuki ユキちゃん、アンディくんおはよう朝からポカポカなお日様を受けてる4ワン...</td>\n",
       "      <td>2013-01-18T23:57:27</td>\n",
       "      <td>/chokotan82/status/292420470807068672</td>\n",
       "      <td>chokotan82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>業平心</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420452163416064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>今空&amp;田んぼだよー pic.twitter.com/HqZQH1B1</td>\n",
       "      <td>2013-01-18T23:57:23</td>\n",
       "      <td>/ncocoro/status/292420452163416064</td>\n",
       "      <td>ncocoro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fullname                                               html  \\\n",
       "0  himitan  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "1  himitan  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "2     ゆかちん  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "3     コミー♪  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "4      業平心  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "\n",
       "                   id likes replies retweets  \\\n",
       "0  292420866954891265     0       0        0   \n",
       "1  292420700034199552     0       0        0   \n",
       "2  292420678207033344     0       0        0   \n",
       "3  292420470807068672     0       1        0   \n",
       "4  292420452163416064     0       0        0   \n",
       "\n",
       "                                                text            timestamp  \\\n",
       "0         @yukyan_MNsy おはようありがとう〜ハンバーグまだあるよ食べにおいで（笑）  2013-01-18T23:59:02   \n",
       "1        @gdgk0x ありがとういらなかったけど（笑）明日もあるけどさすがに飽きるよね（笑）  2013-01-18T23:58:22   \n",
       "2                       @kuwamann0410 おはようステキな目覚めだね♪  2013-01-18T23:58:17   \n",
       "3  @andy_yuki ユキちゃん、アンディくんおはよう朝からポカポカなお日様を受けてる4ワン...  2013-01-18T23:57:27   \n",
       "4                 今空&田んぼだよー pic.twitter.com/HqZQH1B1  2013-01-18T23:57:23   \n",
       "\n",
       "                                      url         user  label  \n",
       "0  /himitan1109/status/292420866954891265  himitan1109      0  \n",
       "1  /himitan1109/status/292420700034199552  himitan1109      0  \n",
       "2   /babys_yuka/status/292420678207033344   babys_yuka      0  \n",
       "3   /chokotan82/status/292420470807068672   chokotan82      0  \n",
       "4      /ncocoro/status/292420452163416064      ncocoro      0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for l, d in zip(labels, data):\n",
    "    tmp = pd.DataFrame(d)\n",
    "    tmp['label'] = l\n",
    "    dfs.append(tmp)\n",
    "df = pd.concat(dfs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "\n",
    "X = df['text'].tolist()\n",
    "y = df['label'].tolist()\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "X = list(map(tagger.parse, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4549884215552878"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class  TfIdfWord2VecVectorizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tfidf_model = TfidfVectorizer(min_df=2, max_df=1000).fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.tfidf_and_w2v(X, self.tfidf_model)\n",
    "\n",
    "    def texts_encoder(self, texts):\n",
    "        with tf.Graph().as_default():\n",
    "            embed = hub.Module(\"https://tfhub.dev/google/nnlm-ja-dim128/1\")\n",
    "            embeddings = embed(texts)\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                sess.run(tf.tables_initializer())\n",
    "                result = sess.run(embeddings)\n",
    "        return result\n",
    "\n",
    "    def tfidf_and_w2v(self, X, tfidf_model):\n",
    "        tmp = tfidf_model.transform(X)\n",
    "        a = tmp.toarray()\n",
    "        if isinstance(X, pd.core.series.Series):\n",
    "            X = X.tolist()\n",
    "        b = self.texts_encoder(X)\n",
    "        return np.hstack((a, b))\n",
    "\n",
    "pipe = Pipeline([('vector',TfIdfWord2VecVectorizer()), (\"clf\", LogisticRegression())])\n",
    "np.mean(cross_val_score(pipe, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vector', <__main__.TfIdfWord2VecVectorizer object at 0x7f0482c52630>), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      happy       0.52      0.60      0.56       252\n",
      "        sad       0.69      0.48      0.57       250\n",
      "    disgust       0.42      0.55      0.48       243\n",
      "      angry       0.43      0.44      0.44       258\n",
      "       fear       0.41      0.41      0.41       256\n",
      "   surprise       0.29      0.24      0.27       241\n",
      "\n",
      "avg / total       0.46      0.45      0.45      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred, target_names=emotions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n"
     ]
    }
   ],
   "source": [
    "proba_test = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpeoivr7x2\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpeoivr7x2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04825ec6a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpeoivr7x2/model.ckpt.\n",
      "INFO:tensorflow:loss = 229.7102, step = 1\n",
      "INFO:tensorflow:global_step/sec: 162.542\n",
      "INFO:tensorflow:loss = 211.7898, step = 101 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.887\n",
      "INFO:tensorflow:loss = 199.42378, step = 201 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.775\n",
      "INFO:tensorflow:loss = 176.86725, step = 301 (0.575 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.168\n",
      "INFO:tensorflow:loss = 175.5055, step = 401 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.932\n",
      "INFO:tensorflow:loss = 160.84796, step = 501 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.5\n",
      "INFO:tensorflow:loss = 125.35509, step = 601 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.775\n",
      "INFO:tensorflow:loss = 87.87791, step = 701 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.706\n",
      "INFO:tensorflow:loss = 91.76838, step = 801 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.508\n",
      "INFO:tensorflow:loss = 68.85502, step = 901 (0.597 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpeoivr7x2/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 68.94926.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-24-02:50:19\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpeoivr7x2/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-24-02:50:20\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.252, average_loss = 2.3210032, global_step = 1000, loss = 290.1254\n",
      "Test set accuracy: 0.25200000405311584\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "n = 6000 - 1500\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    df[:n], df[:n][\"label\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    df[n:], df[n:][\"label\"], shuffle=False)\n",
    "\n",
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "        key=\"text\", \n",
    "        module_spec=\"https://tfhub.dev/google/nnlm-ja-dim128/1\")\n",
    "\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "        hidden_units=[1200, 600, 150],\n",
    "        feature_columns=[embedded_text_feature_column],\n",
    "        n_classes=6,\n",
    "        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, steps=1000);\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.158507809206412"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class  TfIdfWord2VecVectorizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tfidf_model = TfidfVectorizer(min_df=2, max_df=1000).fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.tfidf_and_w2v(X, self.tfidf_model)\n",
    "\n",
    "    def texts_encoder(self, texts):\n",
    "        with tf.Graph().as_default():\n",
    "            embed = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim128/1\")\n",
    "            embeddings = embed(texts)\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                sess.run(tf.tables_initializer())\n",
    "                result = sess.run(embeddings)\n",
    "        return result\n",
    "\n",
    "    def tfidf_and_w2v(self, X, tfidf_model):\n",
    "        tmp = tfidf_model.transform(X)\n",
    "        a = tmp.toarray()\n",
    "        if isinstance(X, pd.core.series.Series):\n",
    "            X = X.tolist()\n",
    "        b = self.texts_encoder(X)\n",
    "        return np.hstack((a, b))\n",
    "\n",
    "dpipe = Pipeline([('vector',TfIdfWord2VecVectorizer()), (\"clf\", DummyClassifier())])\n",
    "np.mean(cross_val_score(dpipe, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.14      0.14      0.14       238\n",
      "          1       0.14      0.14      0.14       242\n",
      "          2       0.21      0.20      0.20       264\n",
      "          3       0.18      0.19      0.19       251\n",
      "          4       0.16      0.14      0.15       269\n",
      "          5       0.17      0.20      0.18       236\n",
      "\n",
      "avg / total       0.17      0.17      0.17      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpipe.fit(X_train, y_train)\n",
    "d_y_pred = dpipe.predict(X_test)\n",
    "print(classification_report(y_test, d_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
