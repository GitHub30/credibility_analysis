{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "emotions = [\"happy\", \"sad\", [\"disgust\", \"disgust2\"], \"angry\", \"fear\", \"surprise\"]\n",
    "lim = 2840\n",
    "for emo in emotions:\n",
    "    if isinstance(emo, list):\n",
    "        tmp = []\n",
    "        for d in emo:\n",
    "            with open(\"{}.json\".format(d), \"r\") as f:\n",
    "                tmp.append(json.load(f))\n",
    "        data.append(sum(tmp, [])[:lim])\n",
    "    elif isinstance(emo, str):\n",
    "        with open(\"{}.json\".format(emo), \"r\") as f:\n",
    "            if emo == \"sad\":\n",
    "                tmp = json.load(f)\n",
    "                data.append([d for d in tmp if \"Love_McD\" not in d['user']][:lim])\n",
    "            else:\n",
    "                data.append(json.load(f)[:lim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [i for i in range(len(emotions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullname</th>\n",
       "      <th>html</th>\n",
       "      <th>id</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>user</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>himitan</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420866954891265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@yukyan_MNsy おはようありがとう〜ハンバーグまだあるよ食べにおいで（笑）</td>\n",
       "      <td>2013-01-18T23:59:02</td>\n",
       "      <td>/himitan1109/status/292420866954891265</td>\n",
       "      <td>himitan1109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>himitan</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420700034199552</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@gdgk0x ありがとういらなかったけど（笑）明日もあるけどさすがに飽きるよね（笑）</td>\n",
       "      <td>2013-01-18T23:58:22</td>\n",
       "      <td>/himitan1109/status/292420700034199552</td>\n",
       "      <td>himitan1109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ゆかちん</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420678207033344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@kuwamann0410 おはようステキな目覚めだね♪</td>\n",
       "      <td>2013-01-18T23:58:17</td>\n",
       "      <td>/babys_yuka/status/292420678207033344</td>\n",
       "      <td>babys_yuka</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>コミー♪</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420470807068672</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@andy_yuki ユキちゃん、アンディくんおはよう朝からポカポカなお日様を受けてる4ワン...</td>\n",
       "      <td>2013-01-18T23:57:27</td>\n",
       "      <td>/chokotan82/status/292420470807068672</td>\n",
       "      <td>chokotan82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>業平心</td>\n",
       "      <td>&lt;p class=\"TweetTextSize js-tweet-text tweet-te...</td>\n",
       "      <td>292420452163416064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>今空&amp;田んぼだよー pic.twitter.com/HqZQH1B1</td>\n",
       "      <td>2013-01-18T23:57:23</td>\n",
       "      <td>/ncocoro/status/292420452163416064</td>\n",
       "      <td>ncocoro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fullname                                               html  \\\n",
       "0  himitan  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "1  himitan  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "2     ゆかちん  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "3     コミー♪  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "4      業平心  <p class=\"TweetTextSize js-tweet-text tweet-te...   \n",
       "\n",
       "                   id likes replies retweets  \\\n",
       "0  292420866954891265     0       0        0   \n",
       "1  292420700034199552     0       0        0   \n",
       "2  292420678207033344     0       0        0   \n",
       "3  292420470807068672     0       1        0   \n",
       "4  292420452163416064     0       0        0   \n",
       "\n",
       "                                                text            timestamp  \\\n",
       "0         @yukyan_MNsy おはようありがとう〜ハンバーグまだあるよ食べにおいで（笑）  2013-01-18T23:59:02   \n",
       "1        @gdgk0x ありがとういらなかったけど（笑）明日もあるけどさすがに飽きるよね（笑）  2013-01-18T23:58:22   \n",
       "2                       @kuwamann0410 おはようステキな目覚めだね♪  2013-01-18T23:58:17   \n",
       "3  @andy_yuki ユキちゃん、アンディくんおはよう朝からポカポカなお日様を受けてる4ワン...  2013-01-18T23:57:27   \n",
       "4                 今空&田んぼだよー pic.twitter.com/HqZQH1B1  2013-01-18T23:57:23   \n",
       "\n",
       "                                      url         user  label  \n",
       "0  /himitan1109/status/292420866954891265  himitan1109      0  \n",
       "1  /himitan1109/status/292420700034199552  himitan1109      0  \n",
       "2   /babys_yuka/status/292420678207033344   babys_yuka      0  \n",
       "3   /chokotan82/status/292420470807068672   chokotan82      0  \n",
       "4      /ncocoro/status/292420452163416064      ncocoro      0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for l, d in zip(labels, data):\n",
    "    tmp = pd.DataFrame(d)\n",
    "    tmp['label'] = l\n",
    "    dfs.append(tmp)\n",
    "df = pd.concat(dfs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17040, 11)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p class=\"TweetTextSize js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"ja\">@NAMAKO7_8 \n",
       "体育祭なんだー\n",
       "たいへんだね！ \n",
       "俺はもう終わった！ あ！でも今週土曜日学校ある<strong><img alt=\"😲\" aria-label=\"Emoji: 驚いた顔\" class=\"Emoji Emoji--forText\" draggable=\"false\" src=\"https://abs.twimg.com/emoji/v2/72x72/1f632.png\" title=\"驚いた顔\"/></strong></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p class=\"TweetTextSize js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"ja\"><a class=\"twitter-atreply pretty-link js-nav\" data-mentioned-user-id=\"189307576\" dir=\"ltr\" href=\"/koichan1110\"><s>@</s><b>koichan1110</b></a> \n",
       "おはようございます(^^)今日も、一日頑張りましょう<strong><img alt=\"😄\" aria-label=\"Emoji: 口を開けて目が笑っている笑顔\" class=\"Emoji Emoji--forText\" draggable=\"false\" src=\"https://abs.twimg.com/emoji/v2/72x72/1f604.png\" title=\"口を開けて目が笑っている笑顔\"/></strong></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p class=\"TweetTextSize js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"ja\">バスくる気配ないで<strong><img alt=\"😨\" aria-label=\"Emoji: ゾッとしている顔\" class=\"Emoji Emoji--forText\" draggable=\"false\" src=\"https://abs.twimg.com/emoji/v2/72x72/1f628.png\" title=\"ゾッとしている顔\"/></strong><img alt=\"💔\" aria-label=\"Emoji: 割れたハート\" class=\"Emoji Emoji--forText\" draggable=\"false\" src=\"https://abs.twimg.com/emoji/v2/72x72/1f494.png\" title=\"割れたハート\"/>しかもめっちゃ混んでる！！あ、めっちゃ遠くにバス見えた（笑）</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p class=\"TweetTextSize js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"ja\"><a class=\"twitter-atreply pretty-link js-nav\" data-mentioned-user-id=\"304425956\" dir=\"ltr\" href=\"/makko5155\"><s>@</s><b>makko5155</b></a> <a class=\"twitter-atreply pretty-link js-nav\" data-mentioned-user-id=\"135232961\" dir=\"ltr\" href=\"/aikawatosaka\"><s>@</s><b>aikawatosaka</b></a> \n",
       "アイカワさん、、、サインをもらってあげるよ<strong><img alt=\"😄\" aria-label=\"Emoji: 口を開けて目が笑っている笑顔\" class=\"Emoji Emoji--forText\" draggable=\"false\" src=\"https://abs.twimg.com/emoji/v2/72x72/1f604.png\" title=\"口を開けて目が笑っている笑顔\"/></strong>\n",
       "cdに(笑)着払い！</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p class=\"TweetTextSize js-tweet-text tweet-text\" data-aria-label-part=\"0\" lang=\"ja\">ありえへん<strong><img alt=\"😨\" aria-label=\"Emoji: ゾッとしている顔\" class=\"Emoji Emoji--forText\" draggable=\"false\" src=\"https://abs.twimg.com/emoji/v2/72x72/1f628.png\" title=\"ゾッとしている顔\"/></strong>\n",
       "深夜に中華と一緒に中華なんて！</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "for i in range(5):\n",
    "    display(HTML(df.iloc[i]['html']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "\n",
    "X = df['text'].tolist()\n",
    "y = df['label'].tolist()\n",
    "tagger = MeCab.Tagger(\"-Owakati\")\n",
    "\n",
    "X = list(map(tagger.parse, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3971239121898487"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class  TfIdfWord2VecVectorizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tfidf_model = TfidfVectorizer().fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.tfidf_and_w2v(X, self.tfidf_model)\n",
    "\n",
    "    def texts_encoder(self, texts):\n",
    "        with tf.Graph().as_default():\n",
    "            embed = hub.Module(\"https://tfhub.dev/google/nnlm-ja-dim128/1\")\n",
    "            embeddings = embed(texts)\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                sess.run(tf.tables_initializer())\n",
    "                result = sess.run(embeddings)\n",
    "        return result\n",
    "\n",
    "    def tfidf_and_w2v(self, X, tfidf_model):\n",
    "        tmp = tfidf_model.transform(X)\n",
    "        a = tmp.toarray()\n",
    "        if isinstance(X, pd.core.series.Series):\n",
    "            X = X.tolist()\n",
    "        b = self.texts_encoder(X)\n",
    "        return np.hstack((a, b))\n",
    "\n",
    "pipe = Pipeline([('vector',TfIdfWord2VecVectorizer()), (\"clf\", LogisticRegression())])\n",
    "np.mean(cross_val_score(pipe, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vector', <__main__.TfIdfWord2VecVectorizer object at 0x7f04835605c0>), ('clf', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      happy       0.49      0.59      0.54       726\n",
      "        sad       0.34      0.39      0.37       619\n",
      "    disgust       0.39      0.48      0.43       730\n",
      "      angry       0.46      0.42      0.44       756\n",
      "       fear       0.35      0.28      0.31       711\n",
      "   surprise       0.31      0.22      0.26       718\n",
      "\n",
      "avg / total       0.39      0.40      0.39      4260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "emotion_names = [\"happy\", \"sad\", \"disgust\", \"angry\", \"fear\", \"surprise\"]\n",
    "print(classification_report(y_test, y_pred, target_names=emotion_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/32f2b2259e1cc8ca58c876921748361283e73997/variables/variables' with embeddings\n"
     ]
    }
   ],
   "source": [
    "proba_test = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp1v6gxtyk\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp1v6gxtyk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0488066390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp1v6gxtyk/model.ckpt.\n",
      "INFO:tensorflow:loss = 229.35922, step = 1\n",
      "INFO:tensorflow:global_step/sec: 171.098\n",
      "INFO:tensorflow:loss = 226.15602, step = 101 (0.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.426\n",
      "INFO:tensorflow:loss = 221.39108, step = 201 (0.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.379\n",
      "INFO:tensorflow:loss = 223.03566, step = 301 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.105\n",
      "INFO:tensorflow:loss = 209.5705, step = 401 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.408\n",
      "INFO:tensorflow:loss = 199.10513, step = 501 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.377\n",
      "INFO:tensorflow:loss = 189.46562, step = 601 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.383\n",
      "INFO:tensorflow:loss = 188.82152, step = 701 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.09\n",
      "INFO:tensorflow:loss = 184.69724, step = 801 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.58\n",
      "INFO:tensorflow:loss = 161.9725, step = 901 (0.548 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp1v6gxtyk/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 169.1178.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable dnn/input_from_feature_columns/input_layer/text_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-24-05:06:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp1v6gxtyk/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-24-05:06:15\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.20808458, average_loss = 1.8927566, global_step = 1000, loss = 241.55179\n",
      "Test set accuracy: 0.2080845832824707\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "n = 12000 - 3000\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    df[:n], df[:n][\"label\"], num_epochs=None, shuffle=True)\n",
    "\n",
    "predict_test_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    df[n:], df[n:][\"label\"], shuffle=False)\n",
    "\n",
    "embedded_text_feature_column = hub.text_embedding_column(\n",
    "        key=\"text\", \n",
    "        module_spec=\"https://tfhub.dev/google/nnlm-ja-dim128/1\")\n",
    "\n",
    "estimator = tf.estimator.DNNClassifier(\n",
    "        hidden_units=[1200, 600, 150],\n",
    "        feature_columns=[embedded_text_feature_column],\n",
    "        n_classes=6,\n",
    "        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003))\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, steps=1000);\n",
    "test_eval_result = estimator.evaluate(input_fn=predict_test_input_fn)\n",
    "print(\"Test set accuracy: {accuracy}\".format(**test_eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1620901309452671"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpipe = Pipeline([('vector',TfIdfWord2VecVectorizer()), (\"clf\", DummyClassifier())])\n",
    "np.mean(cross_val_score(dpipe, X, y, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      happy       0.16      0.15      0.15       726\n",
      "        sad       0.16      0.19      0.17       619\n",
      "    disgust       0.17      0.18      0.17       730\n",
      "      angry       0.18      0.16      0.17       756\n",
      "       fear       0.17      0.17      0.17       711\n",
      "   surprise       0.16      0.16      0.16       718\n",
      "\n",
      "avg / total       0.17      0.17      0.17      4260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpipe.fit(X_train, y_train)\n",
    "d_y_pred = dpipe.predict(X_test)\n",
    "print(classification_report(y_test, d_y_pred, target_names=emotion_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2840, 2840, 2840, 2840, 2840, 2840]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/22c95b8e6878e472b6647f65afb10d88cafc52e0/variables/variables' with embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['やったー うれしい ！ \\n', '最悪 ... 死ね \\n', 'この 野郎 、 ぶっ た おす \\n'],\n",
       " array([[0.25946001, 0.13732661, 0.32607777, 0.07504031, 0.04833197,\n",
       "         0.15376333],\n",
       "        [0.00487579, 0.11895783, 0.22373823, 0.23420281, 0.37829694,\n",
       "         0.0399284 ],\n",
       "        [0.05746742, 0.04949165, 0.22222228, 0.48779324, 0.10251502,\n",
       "         0.0805104 ]]),\n",
       " array([[-1.13207872, -1.90959561, -0.81715024, -2.57896222, -3.04553395,\n",
       "         -1.77865301],\n",
       "        [-5.26139413, -1.93749432, -1.17008739, -1.10975529, -0.40359856,\n",
       "         -3.12057717],\n",
       "        [-2.74302125, -2.90133036, -1.18653385,  0.05353867, -2.11244961,\n",
       "         -2.37970112]]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, pipe.predict_proba(examples), pipe.decision_function(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
