{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UrlGetter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_asyura_url(self, page):\n",
    "        return \"http://rank.asyura3.com/sogo/999/{}/\".format(page)\n",
    "    \n",
    "    def get_litera_url(self, year, month, page):\n",
    "        if isinstance(page, int) and isinstance(month, int) and isinstance(year, int):\n",
    "            if page==1:\n",
    "                filename = \"index.html\"\n",
    "            elif page > 1:\n",
    "                filename = \"index_{}.html\".format(page)\n",
    "            else:\n",
    "                filename = \"index.html\"\n",
    "            return \"http://lite-ra.com/{}/{:02d}/{}\".format(year, month, filename)\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def get_mainichi_url(self, page):\n",
    "        return \"https://mainichi.jp/flash/{}\".format(page)\n",
    "        \n",
    "    def get_url(self, site_type, *params):\n",
    "        return getattr(self, \"get_{}_url\".format(site_type))(*params)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleGetter:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        r = requests.get(base_url)\n",
    "        self.soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    \n",
    "    def get_asyura_articles(self):\n",
    "        results = [result['href'] for result in set([tmp_result.find(\"a\") for tmp_result in self.soup.find_all(\"td\", attrs={\"class\":\"cell\"})]) if result is not None]\n",
    "        return results\n",
    "    \n",
    "    def get_litera_articles(self):\n",
    "        results = [result['href'] for result in set([tmp_result.find(\"a\") for tmp_result in self.soup.find_all(\"h2\", attrs={\"class\":\"entryTitle\"})])]\n",
    "        return results\n",
    "    \n",
    "    def get_mainichi_articles(self):\n",
    "        section = self.soup.find(\"section\", {\"class\":\"newslist\"})\n",
    "        results = [\"http:\"+result['href'] for result in set(section.find_all(\"a\")) if 'class' not in result]\n",
    "        return results\n",
    "    \n",
    "    def get_articles(self, site_type):\n",
    "        return getattr(self, \"get_{}_articles\".format(site_type))()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleExtractor:\n",
    "    def __init__(self, target_url):\n",
    "        self.target_url = target_url\n",
    "        r = requests.get(target_url)\n",
    "        self.soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        [s.extract() for s in self.soup('script')]\n",
    "        [s.extract() for s in self.soup('link')]\n",
    "        \n",
    "    def extract_asyura_article(self):\n",
    "        pass\n",
    "    \n",
    "    def extract_litera_article(self):\n",
    "        title = self.soup.find(\"h1\", attrs={\"id\":\"entryTitle\"}).get_text()\n",
    "        body = self.soup.find(\"div\", attrs={\"id\":\"entryBody\"}).get_text()\n",
    "        return title, body\n",
    "    \n",
    "    def extract_mainichi_article(self):\n",
    "        title = self.soup.find(\"h1\").get_text()\n",
    "        body = ' '.join([result.get_text() for result in self.soup.find_all(\"p\", {\"class\":\"txt\"})])\n",
    "        return title, body\n",
    "    \n",
    "    def extract_article(self, site_type):\n",
    "        title, body = getattr(self, \"extract_{}_article\".format(site_type))()\n",
    "        title = title.replace(\"\\n\", \" \").replace(\"\\u3000\", \" \").replace(\"\\r\",\"\")\n",
    "        body = body.replace(\"\\n\", \" \").replace(\"\\u3000\", \" \").replace(\"\\r\", \"\")\n",
    "        return title, body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' 海岸の美、競演 鳥取・琴浦町',\n",
       " '      波に洗われて角がとれた楕円（だえん）の石が多数存在する海岸「鳴り石の浜」（鳥取県琴浦町）で、石を絶妙に積み上げる「ストーン（ロック）バランシング」が人気だ。これらの作品と夕日などを絡めた幻想的な風景が写真共有アプリ「インスタグラム」に投稿されている。造形の美しさを競うコンテストも催されており、海岸の魅力アップに一役買っている。【阿部絢美】        コンテストを企画したのは２０１１年発足の、地元有志でつくる団体「鳴り石の浜プロジェクト」。これまで、海岸近くで大輪のヒマワリを咲かせたり、石を絵馬に見立てて願い事を書いて海に投げるといった「石絵馬祈願」を始めたりと興味を引く仕掛けを作ってきた。今回メンバーの一人が海外で人気なストーンバランシングを知ったのがきっかけ。サブリーダーの上田啓悟さん（４６）は「面白いものをたくさん取り入れ、魅力をどんどん発信していきたい」を意気込む。        鳴り石の浜は１０年前まで韓国や中国などのゴミが大量に漂流し、観光スポットとはほど遠い存在。５０年ほど海岸の保全活動を続けている岩田弘さん（８２）は「石がこすり合って鳴る『カラン』『ゴロン』という音に地元住民は育てられた。最近はなかなか知られていなくて悲しい」とこぼす。試みについて「同じ形のない石を積み上げて、はやりのＳＮＳに投稿するなんて面白い。多くの人に足を運んでもらえる場所になればうれしい」とほほえむ。        コンテストは鳴り石の浜で石を積み上げて撮影した写真を、メール（info@nariishi.com）で送るか、フェイスブックの同プロジェクトのページに投稿する。１１月３０日まで。審査員の評価が高かったり、同意を示す「いいね！」の数が多かったりした作品は「鳴り石の浜」の看板に採用し、現地に展示される。   「この子は愛から生まれたわけじゃない。私は育てられない」。…  「風邪」や中耳炎、胃腸炎を訴える患者に出されることが多い抗…  ＜くらしナビ ライフスタイル Ｓｅｃｏｎｄ Ｓｔａｇｅ＞ … [PR]')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_type = \"mainichi\"\n",
    "params = [2]\n",
    "urlgetter = UrlGetter()\n",
    "base_url = urlgetter.get_url(site_type, *params)\n",
    "target_url = ArticleGetter(base_url).get_articles(site_type)[0]\n",
    "ArticleExtractor(target_url).extract_article(site_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282b13cd606f4820ac84af488a3065a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3959abe2d207424ca52b43f163c0f714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34ac8f2fd4d4c9bb5a81ceae154530e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "results = []\n",
    "names = [\"mainichi\", \"litera\", \"litera\"]\n",
    "params = [\n",
    "    [],\n",
    "    [2017, 12],\n",
    "    [2017, 11],\n",
    "]\n",
    "\n",
    "pages = [\n",
    "    20,\n",
    "    10,\n",
    "    10,\n",
    "]\n",
    "\n",
    "labels = [False, True, True]\n",
    "\n",
    "for name, param, page_len, label in zip(names, params, pages, labels):\n",
    "    for i in tqdm_notebook(range(page_len)):\n",
    "        base_url = urlgetter.get_url(name, *param, i+1)\n",
    "        for article_url in ArticleGetter(base_url).get_articles(name):\n",
    "            title, body = ArticleExtractor(article_url).extract_article(name)\n",
    "            results.append({\"title\":title, \"body\":body, \"url\": article_url, \"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ceb4412f57e4b69b9ab9b969fb71501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bc3c98025741ffa4ce25741bd04407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0c54cce6624838865382e88afb45b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b48a47a64dc4480a2b022c260912361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1250b102db47e89a8fef4e5eb3014c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2d0279eb004e61af91c73caf83ea73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a6ffd23a9f4e7a85a1405cb2429636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96f717cb83341e1963c4a376a8ffc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6c4f3f66f74de2ba11203c80f61cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9956417fec4db299d396e842466c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = [\"litera\" for i in range(10)]\n",
    "params = [\n",
    "    [2017, 10],\n",
    "    [2017, 9],\n",
    "    [2017, 8],\n",
    "    [2017, 7],\n",
    "    [2017, 6],\n",
    "    [2017, 5],\n",
    "    [2017, 4],\n",
    "    [2017, 3],\n",
    "    [2017, 2],\n",
    "    [2017, 1]\n",
    "]\n",
    "\n",
    "pages = [10 for i in range(10)]\n",
    "\n",
    "labels = [True for i in range(10)]\n",
    "\n",
    "for name, param, page_len, label in zip(names, params, pages, labels):\n",
    "    for i in tqdm_notebook(range(page_len)):\n",
    "        base_url = urlgetter.get_url(name, *param, i+1)\n",
    "        for article_url in ArticleGetter(base_url).get_articles(name):\n",
    "            title, body = ArticleExtractor(article_url).extract_article(name)\n",
    "            results.append({\"title\":title, \"body\":body, \"url\": article_url, \"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
